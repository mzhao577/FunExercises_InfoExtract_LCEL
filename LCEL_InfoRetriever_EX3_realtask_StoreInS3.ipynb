{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dab124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-iiP1T6p4dKPxH4Hn3Y0D3B0gqPqPwEpdDeSRxxhgABT3BlbkFJPUq8Jb-fqOSXJzUtDVtpvdG34DEHTtS7eVr9MqQlcA\n"
     ]
    }
   ],
   "source": [
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "#_ = load_dotenv(find_dotenv()) \n",
    "_ = load_dotenv(dotenv_path=\"/Users/maxzhao/.env\") \n",
    "print(os.environ[\"OPENAI_API_KEY\"]),\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]\n",
    "AWS_ACCESS_KEY_ID=os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "AWS_SECRECT_ACCESS_KEY=os.environ[\"AWS_SECRECT_ACCESS_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15626162-c934-4618-a9c8-fee6c522c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1f9777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded llm_extract/test.json to gz5427\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRECT_ACCESS_KEY,\n",
    "    region_name='us-east-1'  # e.g., 'us-west-1'\n",
    ")\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Your JSON object\n",
    "data = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"New York\"\n",
    "}\n",
    "\n",
    "# Convert JSON object to string\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "# Define your bucket name and the desired object name (key)\n",
    "bucket_name = 'gz5427'\n",
    "object_name = 'llm_extract/test.json'\n",
    "\n",
    "# Upload JSON string to S3\n",
    "s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "\n",
    "print(f\"Uploaded {object_name} to {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75dc4a0-a224-4ed4-bcdb-4c4bde38b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep langchain\n",
    "#langchain==0.3.0\n",
    "#langchain-community==0.3.0\n",
    "#langchain-core==0.3.5\n",
    "#langchain-openai==0.2.0\n",
    "#langchain-text-splitters==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a00bb1-badc-4417-a143-922dc48b6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep openai\n",
    "#langchain-openai==0.2.0\n",
    "#openai==1.47.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e6ec97-58ec-49ff-811f-5cb2a7723d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep pydantic\n",
    "#pydantic==2.9.2\n",
    "#pydantic-settings==2.5.2\n",
    "#pydantic_core==2.23.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4519d",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19ed8e-2f13-4297-b2b7-5989f33bb9ad",
   "metadata": {},
   "source": [
    "## Doing it for real\n",
    "\n",
    "We can apply tagging to a larger body of text.\n",
    "\n",
    "For example, let's load this blog post and extract tag information from a sub-set of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6fd0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "#from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93744538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the elephant bring a suitcase to the jungle? \\n\\nBecause he wanted to pack his trunk!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "template = \"\"\"You are ahelpful assistant. Please hlep me to answer the questions.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"Please tell me a joke about this animal: {animal}\")\n",
    "])\n",
    "\n",
    "chain=prompt | model | StrOutputParser()  \n",
    "\n",
    "chain.invoke({\"animal\":\"elephant\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17eb24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USER_AGENT'] = 'myagent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "594992ea-dc82-4029-ad11-5fc9abd306a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe5655e2-03f4-4e56-acaa-846ed07fce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbef960d-d379-4bd5-9832-3205a67eb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a32280a-0a59-44ab-96b5-419d2d829b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    langugae: str = Field(description=\"Provide the languge that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc950c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b77f9809-7d03-40ef-86ad-2c0ad5b95f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'The article discusses building autonomous agents powered by LLM (large language model) as the core controller, focusing on planning, memory, and tool use components.',\n",
       " 'langugae': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "overview_tagging_function = [convert_to_openai_function(Overview)]\n",
    "tagging_model = model.bind(functions=overview_tagging_function, function_call={\"name\":\"Overview\"})\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser(key_name=\"overview\")\n",
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f3d5ae-ce34-449f-a7e2-e9424b6a0f4b",
   "metadata": {},
   "source": [
    "Now let's try to extract all papers mentioned in this article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b13e373e-b6e5-4fd3-be65-731e738ffb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c261180-9f33-455f-b10d-22608b118d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_function = [convert_to_openai_function(Info)]\n",
    "extraction_model = model.bind(functions=paper_extraction_function, function_call={\"name\":\"Info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "680f7d81-3b7b-4c22-a742-ae2fadc88611",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7786307-09f7-4f26-b52b-91b00adb01e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LLM Powered Autonomous Agents', 'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08b2425-2b50-4015-aa9f-74931b30af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06b5eb24-53ee-4bf3-b560-18e9f503e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d52a51b8-6151-4baf-9fe9-8952bf46ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': None},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': None},\n",
       " {'title': 'LLM+P (Liu et al. 2023)', 'author': None},\n",
       " {'title': 'ReAct (Yao et al. 2023)', 'author': None},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)', 'author': None},\n",
       " {'title': 'Chain of Hindsight (CoH; Liu et al. 2023)', 'author': None},\n",
       " {'title': 'Algorithm Distillation (AD; Laskin et al. 2023)', 'author': None}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e73ccaa7-970a-4de4-a096-9c7f35030582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3867870a-9789-4b9b-9a1a-87947a6afdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e76672b6-dd97-419b-bd00-4186132a1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f1b5d34-3c3b-4a1f-a0d2-1d9289379f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b31012-236c-41ba-8e61-97d533991463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a354b1a9-ca3a-4e10-a9db-128fd3ccb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0fd4bdc-be2c-4bab-abc8-0a828caff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableLambda(lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)])\n",
    "    | extraction_chain.map()\n",
    "    | flatten\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d2d965a-d379-4ec9-8941-d5f00bf65e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc9c9d",
   "metadata": {},
   "source": [
    "## Store data into s3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfb50add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded llm_extract/extracted_Fromweb.json to gz5427\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRECT_ACCESS_KEY,\n",
    "    region_name='us-east-1'  # e.g., 'us-west-1'\n",
    ")\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Convert JSON object to string\n",
    "json_data = json.dumps(output)\n",
    "\n",
    "# Define your bucket name and the desired object name (key)\n",
    "bucket_name = 'gz5427'\n",
    "object_name = 'llm_extract/extracted_Fromweb.json'\n",
    "\n",
    "# Upload JSON string to S3\n",
    "s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "\n",
    "print(f\"Uploaded {object_name} to {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bae0e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Method 1: Use this function to store data into S3.\n",
    "####.           This is probabaly the easiest way and easy to debug.\n",
    "def storeintoS3(data, bucketname, filepath):\n",
    "    import boto3\n",
    "    import json\n",
    "\n",
    "    # Initialize a session using your AWS credentials\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRECT_ACCESS_KEY,\n",
    "        region_name='us-east-1'  # e.g., 'us-west-1'\n",
    "    )\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    # Convert JSON object to string\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # Upload JSON string to S3\n",
    "    s3.put_object(Bucket=bucketname, Key=filepath, Body=json_data)\n",
    "    \n",
    "storeintoS3(data=output, bucketname='gz5427', filepath='llm_extract/testlcel_v3.json')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f13ea83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Method 1: Use the runable to store data into S3.\n",
    "####.           Right now, this works for just one input!!!! \n",
    "def storeintoS3(data):\n",
    "    import boto3\n",
    "    import json\n",
    "\n",
    "    # Initialize a session using your AWS credentials\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRECT_ACCESS_KEY,\n",
    "        region_name='us-east-1'  # e.g., 'us-west-1'\n",
    "    )\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    # Convert JSON object to string\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # Define your bucket name and the desired object name (key)\n",
    "    bucket_name = 'gz5427'\n",
    "    object_name = 'llm_extract/testlcel_v20.json'\n",
    "\n",
    "    # Upload JSON string to S3\n",
    "    s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa3c0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)])\n",
    "    | extraction_chain.map()\n",
    "    | flatten\n",
    "    | storeintoS3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ec3d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "697f011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####. Method 3:  Pass 3 parameter, yet not working now.\n",
    "####             Need some debugging if we want to make it work for rua=nnable.\n",
    "\n",
    "def storeintoS3_passthrough(input):\n",
    "    import boto3\n",
    "    import json\n",
    "\n",
    "    # Initialize a session using your AWS credentials\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRECT_ACCESS_KEY,\n",
    "        region_name='us-east-1'  # e.g., 'us-west-1'\n",
    "    )\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    # Convert JSON object to string\n",
    "    #json_data = json.dumps(input[0])\n",
    "    json_data = json.dumps(input['data'])\n",
    "\n",
    "    # Define your bucket name and the desired object name (key)\n",
    "    bucket_name = input['bucket_name']\n",
    "    object_name = input['filepath']\n",
    "\n",
    "    # Upload JSON string to S3\n",
    "    s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22e79cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storeintoS3(data=output, bucketname='gz5427', filepath='llm_extract/output_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "66d4ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####. Need some debugging!!!!!!!\n",
    "#####. Need some debugging!!!!!!!\n",
    "#####. Need some debugging!!!!!!!\n",
    "#####. Need some debugging!!!!!!!\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)])\n",
    "    | extraction_chain.map()\n",
    "    | flatten\n",
    "    | RunnableParallel(data=RunnablePassthrough(),bucket_name=lambda x: 'gz5427',object_name=lambda x: 'llm_extract/passthrough_testlcel.json'  ) \n",
    "    | storeintoS3_passthrough\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3131e636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(lambda x: [{'input': doc} for doc in text_splitter.split_text(x)])\n",
       "| RunnableEach(bound=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \\n\\nDo not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\\n\\nDo not make up or guess ANY extra information. Only extract what exactly is in the text.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "  | RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10b16c0e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10b191490>, root_client=<openai.OpenAI object at 0x10aef5130>, root_async_client=<openai.AsyncOpenAI object at 0x10b191730>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'functions': [{'name': 'Info', 'description': 'Information to extract', 'parameters': {'properties': {'papers': {'items': {'description': 'Information about papers mentioned.', 'properties': {'title': {'type': 'string'}, 'author': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}}, 'required': ['title', 'author'], 'type': 'object'}, 'type': 'array'}}, 'required': ['papers'], 'type': 'object'}}], 'function_call': {'name': 'Info'}}, config={}, config_factories=[])\n",
       "  | JsonKeyOutputFunctionsParser(key_name='papers'))\n",
       "| RunnableLambda(flatten)\n",
       "| {\n",
       "    data: RunnablePassthrough(),\n",
       "    bucket_name: RunnableLambda(...),\n",
       "    object_name: RunnableLambda(...)\n",
       "  }\n",
       "| RunnableLambda(storeintoS3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2=chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bfacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b272cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7ef9657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'304413155178'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_client = boto3.client('sts')\n",
    "\n",
    "# Call the GetCallerIdentity operation to retrieve the account ID\n",
    "response = sts_client.get_caller_identity()\n",
    "account_id = response['Account']\n",
    "account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27e4adb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57527712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcel_agents",
   "language": "python",
   "name": "lcel_agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
