{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15626162-c934-4618-a9c8-fee6c522c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "####.  Please use VirttualEnv: LCEL_extracting\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "print(os.environ[\"OPENAI_API_KEY\"]),\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75dc4a0-a224-4ed4-bcdb-4c4bde38b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.3.0\r\n",
      "langchain-community==0.3.0\r\n",
      "langchain-core==0.3.5\r\n",
      "langchain-openai==0.2.0\r\n",
      "langchain-text-splitters==0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep langchain\n",
    "#langchain==0.3.0\n",
    "#langchain-community==0.3.0\n",
    "#langchain-core==0.3.5\n",
    "#langchain-openai==0.2.0\n",
    "#langchain-text-splitters==0.3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a00bb1-badc-4417-a143-922dc48b6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain-openai==0.2.0\r\n",
      "openai==1.47.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep openai\n",
    "#langchain-openai==0.2.0\n",
    "#openai==1.47.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e6ec97-58ec-49ff-811f-5cb2a7723d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic==2.9.2\r\n",
      "pydantic-settings==2.5.2\r\n",
      "pydantic_core==2.23.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep pydantic\n",
    "#pydantic==2.9.2\n",
    "#pydantic-settings==2.5.2\n",
    "#pydantic_core==2.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4519d",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c66f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa75472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736b10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3442cf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'properties': {'people': {'description': 'List of info about people',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ed1ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 96, 'total_tokens': 117, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c0c6cdb2-dee5-46af-a429-2d5b1692a81c-0', usage_metadata={'input_tokens': 96, 'output_tokens': 21, 'total_tokens': 117})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_functions = [convert_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\":\"Information\"})\n",
    "extraction_model.invoke(\"Joe is 30. Joe's mom is Martha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62f305",
   "metadata": {},
   "source": [
    "Similarly we can use a separate output parser to pluck that \"Information\" key, since that's the information we really care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19deb56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "extraction_chain = extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")\n",
    "extraction_chain.invoke(\"Joe is 30. Joe's mom is Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11486d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbaa189-a553-47f9-9f29-2d85e3991c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492da33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30. Joe's mom is Martha\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcel_extracting",
   "language": "python",
   "name": "lcel_extracting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
